{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Create a Spark DataFrame with 10 columns\n",
    "df = spark.createDataFrame([\n",
    "  (1, \"John\", \"Doe\", 25, \"M\", \"NY\", \"USA\", \"123456789\", \"john.doe@example.com\", \"active\"),\n",
    "  (2, \"Jane\", \"Doe\", 30, \"F\", \"CA\", \"USA\", \"987654321\", \"jane.doe@example.com\", \"inactive\"),\n",
    "  (3, \"Jim\", \"Smith\", 35, \"M\", \"TX\", \"USA\", \"121212121\", \"jim.smith@example.com\", \"active\"),\n",
    "  (4, \"Joan\", \"Smith\", 40, \"F\", \"FL\", \"USA\", \"343434343\", \"joan.smith@example.com\", \"inactive\"),\n",
    "  (5, \"Jake\", \"Johnson\", 45, \"M\", \"AZ\", \"USA\", \"565656565\", \"jake.johnson@example.com\", \"active\")\n",
    "], [\"id\", \"first_name\", \"last_name\", \"age\", \"gender\", \"state\", \"country\", \"zipcode\", \"email\", \"status\"])\n",
    "\n",
    "# Write the DataFrame as a Delta table with schema evolution enabled\n",
    "df.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").save(\"/mnt/delta/customers\")\n",
    "\n",
    "# Read the Delta table\n",
    "delta_table = spark.read.format(\"delta\").load(\"/mnt/delta/customers\")\n",
    "\n",
    "# Create a new DataFrame with only 4 columns\n",
    "df2 = spark.createDataFrame([\n",
    "  (6, \"John\", \"Smith\", 50),\n",
    "  (7, \"Jane\", \"Johnson\", 55),\n",
    "  (8, \"Jim\", \"Williams\", 60),\n",
    "  (9, \"Joan\", \"Jones\", 65),\n",
    "  (10, \"Jake\", \"Brown\", 70)\n",
    "], [\"id\", \"first_name\", \"last_name\", \"age\"])\n",
    "\n",
    "# Append the new DataFrame to the Delta table\n",
    "df2.write.format(\"delta\").mode(\"append\").save(\"/mnt/delta/customers\")\n",
    "\n",
    "# Read the updated Delta table\n",
    "delta_table = spark.read.format(\"delta\").load(\"/mnt/delta/customers\")\n",
    "\n",
    "# Verify the schema evolution\n",
    "delta_table.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark DataFrame with 10 columns\n",
    "df = spark.createDataFrame([\n",
    "  (1, \"John\", \"Doe\", 25, \"M\", \"NY\", \"USA\", \"123456789\", \"john.doe@example.com\", \"active\"),\n",
    "  (2, \"Jane\", \"Doe\", 30, \"F\", \"CA\", \"USA\", \"987654321\", \"jane.doe@example.com\", \"inactive\"),\n",
    "  (3, \"Jim\", \"Smith\", 35, \"M\", \"TX\", \"USA\", \"121212121\", \"jim.smith@example.com\", \"active\"),\n",
    "  (4, \"Joan\", \"Smith\", 40, \"F\", \"FL\", \"USA\", \"343434343\", \"joan.smith@example.com\", \"inactive\"),\n",
    "  (5, \"Jake\", \"Johnson\", 45, \"M\", \"AZ\", \"USA\", \"565656565\", \"jake.johnson@example.com\", \"active\")\n",
    "], [\"id\", \"first_name\", \"last_name\", \"age\", \"gender\", \"state\", \"country\", \"zipcode\", \"email\", \"status\"])\n",
    "\n",
    "# Create a temporary view of the DataFrame\n",
    "df.createOrReplaceTempView(\"customers\")\n",
    "\n",
    "# Write the DataFrame as a Delta table with schema evolution enabled\n",
    "spark.sql(\"\"\"\n",
    "  CREATE TABLE customers_delta\n",
    "  USING delta\n",
    "  OPTIONS ('mergeSchema' 'true')\n",
    "  AS SELECT * FROM customers\n",
    "\"\"\")\n",
    "\n",
    "# Create a new DataFrame with only 4 columns\n",
    "df2 = spark.createDataFrame([\n",
    "  (6, \"John\", \"Smith\", 50),\n",
    "  (7, \"Jane\", \"Johnson\", 55),\n",
    "  (8, \"Jim\", \"Williams\", 60),\n",
    "  (9, \"Joan\", \"Jones\", 65),\n",
    "  (10, \"Jake\", \"Brown\", 70)\n",
    "], [\"id\", \"first_name\", \"last_name\", \"age\"])\n",
    "\n",
    "# Create a temporary view of the new DataFrame\n",
    "df2.createOrReplaceTempView(\"customers2\")\n",
    "\n",
    "# Append the new DataFrame to the Delta table\n",
    "spark.sql(\"\"\"\n",
    "  INSERT INTO customers_delta\n",
    "  SELECT * FROM customers2\n",
    "\"\"\")\n",
    "\n",
    "# Read the updated Delta table\n",
    "delta_table = spark.read.format(\"delta\").load(\"/mnt/delta/customers_delta\")\n",
    "\n",
    "# Verify the schema evolution\n",
    "delta_table.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7 (default, Oct 12 2021, 22:38:23) \n[Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
