{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Demo\n",
    "## Credit: Eric Elmoznino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "Predict wage_per_hour from various features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/hourly_wages_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "X = df.drop(columns=['wage_per_hour'])\n",
    "y = df[['wage_per_hour']]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice no feature preparation or engineering.\n",
    "\n",
    "---\n",
    "# Train a multi-layer perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 161.0733 - val_loss: 120.9714\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 96.1672 - val_loss: 70.3283\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 57.5093 - val_loss: 44.4108\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 39.3334 - val_loss: 32.8888\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 33.3180 - val_loss: 30.0860\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 32.1471 - val_loss: 29.0599\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 31.1056 - val_loss: 28.1576\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 30.2525 - val_loss: 27.3919\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 29.2409 - val_loss: 26.5463\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 28.4239 - val_loss: 25.6999\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.6927 - val_loss: 24.8798\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 26.9221 - val_loss: 24.1590\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 26.2411 - val_loss: 23.5326\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 25.5903 - val_loss: 22.8111\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 24.9046 - val_loss: 22.0972\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 24.2011 - val_loss: 21.1360\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 23.6693 - val_loss: 20.7957\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 23.3267 - val_loss: 20.5068\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 23.1114 - val_loss: 20.0792\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.8721 - val_loss: 20.1996\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.7655 - val_loss: 19.8882\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.6335 - val_loss: 19.7201\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.5892 - val_loss: 19.7299\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.5051 - val_loss: 19.5476\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.4859 - val_loss: 19.7373\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.4482 - val_loss: 19.3221\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.2554 - val_loss: 19.4112\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.3358 - val_loss: 19.3889\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.1532 - val_loss: 19.1248\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.2000 - val_loss: 19.2227\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.1801 - val_loss: 19.0453\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.0492 - val_loss: 19.3283\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.0745 - val_loss: 18.9727\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.9661 - val_loss: 19.1638\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.9754 - val_loss: 18.9131\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.9587 - val_loss: 18.9546\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.7943 - val_loss: 18.7802\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.9071 - val_loss: 18.8240\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.7375 - val_loss: 18.8117\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.7211 - val_loss: 18.7285\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.7195 - val_loss: 18.7723\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.6037 - val_loss: 18.6045\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.6228 - val_loss: 18.6173\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.5354 - val_loss: 18.5619\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.4957 - val_loss: 18.5303\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.4660 - val_loss: 18.6188\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.5379 - val_loss: 18.4400\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.4758 - val_loss: 18.4790\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.3936 - val_loss: 18.4509\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.4042 - val_loss: 18.3046\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.2755 - val_loss: 18.4113\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.2599 - val_loss: 18.3019\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.2265 - val_loss: 18.3906\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.2115 - val_loss: 18.1762\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.2000 - val_loss: 18.2102\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.1339 - val_loss: 18.2531\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.1133 - val_loss: 18.1652\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.2279 - val_loss: 18.1458\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.1426 - val_loss: 18.0351\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.0034 - val_loss: 18.3189\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.0353 - val_loss: 18.0661\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 21.0020 - val_loss: 18.0710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220453c99d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential        # Helper to build a network from a sequence of layers\n",
    "from tensorflow.keras.layers import Dense             # Fully-connected layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # To stop training early if val loss stops decreasing\n",
    "\n",
    "# Create the model (num_features -> 10 -> 10 -> 1)\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Train the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')    # Builds the static computation graph\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, \n",
    "          callbacks=[EarlyStopping(patience=3)], verbose=1)\n",
    "# defining 'validation_data' will also print validation loss alongside training loss\n",
    "# callbacks contain extra little settings or features during training\n",
    "# EarlyStopping with patience will stop training early if val_loss didnt get lower after 3 epochs (prevent over-fitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we don't need to calculate some evaluation metric (on the validation set) after the NN is trained, since it is represented by the calculated loss (val_loss).\n",
    "\n",
    "We can make predictions using `.predict`. This just runs the input data through the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.6152525],\n",
       "       [ 7.3729324],\n",
       "       [ 8.301231 ],\n",
       "       [ 8.792376 ],\n",
       "       [ 8.156644 ],\n",
       "       [ 8.835825 ],\n",
       "       [10.238572 ],\n",
       "       [10.573337 ],\n",
       "       [ 7.7762814],\n",
       "       [ 9.5570965],\n",
       "       [ 8.029222 ],\n",
       "       [ 7.531453 ],\n",
       "       [13.647486 ],\n",
       "       [ 8.302068 ],\n",
       "       [ 9.335474 ],\n",
       "       [10.497734 ],\n",
       "       [11.34775  ],\n",
       "       [11.42631  ],\n",
       "       [10.040042 ],\n",
       "       [ 7.319248 ],\n",
       "       [ 8.204308 ],\n",
       "       [10.060274 ],\n",
       "       [ 8.127461 ],\n",
       "       [11.41017  ],\n",
       "       [11.251994 ],\n",
       "       [ 9.574636 ],\n",
       "       [ 8.593909 ],\n",
       "       [ 8.750599 ],\n",
       "       [ 9.475721 ],\n",
       "       [ 9.063465 ],\n",
       "       [10.965584 ],\n",
       "       [ 8.966171 ],\n",
       "       [ 6.688916 ],\n",
       "       [10.249067 ],\n",
       "       [ 7.318857 ],\n",
       "       [ 7.842854 ],\n",
       "       [ 9.822768 ],\n",
       "       [ 8.301231 ],\n",
       "       [ 8.620252 ],\n",
       "       [ 7.2402153],\n",
       "       [ 9.205982 ],\n",
       "       [12.778341 ],\n",
       "       [10.477993 ],\n",
       "       [ 8.511211 ],\n",
       "       [10.273439 ],\n",
       "       [ 7.9062285],\n",
       "       [ 7.655777 ],\n",
       "       [ 7.8498898],\n",
       "       [ 7.014577 ],\n",
       "       [11.178322 ],\n",
       "       [ 7.4490833],\n",
       "       [ 6.498362 ],\n",
       "       [ 8.193443 ],\n",
       "       [ 6.863639 ],\n",
       "       [10.43517  ],\n",
       "       [ 8.966172 ],\n",
       "       [ 6.625934 ],\n",
       "       [ 9.173346 ],\n",
       "       [ 6.222115 ],\n",
       "       [ 9.04719  ],\n",
       "       [ 7.5829124],\n",
       "       [11.843313 ],\n",
       "       [10.890654 ],\n",
       "       [ 9.969746 ],\n",
       "       [10.3579035],\n",
       "       [ 8.197195 ],\n",
       "       [ 8.3441925],\n",
       "       [ 7.975147 ],\n",
       "       [ 9.259666 ],\n",
       "       [ 8.554813 ],\n",
       "       [ 8.738065 ],\n",
       "       [ 9.387735 ],\n",
       "       [10.119186 ],\n",
       "       [ 9.956151 ],\n",
       "       [ 7.5829124],\n",
       "       [10.591343 ],\n",
       "       [ 8.781513 ],\n",
       "       [ 8.67289  ],\n",
       "       [ 8.824963 ],\n",
       "       [ 8.88362  ],\n",
       "       [11.236687 ],\n",
       "       [ 9.671387 ],\n",
       "       [ 8.873081 ],\n",
       "       [ 7.4079623],\n",
       "       [13.0282   ],\n",
       "       [ 7.4445534],\n",
       "       [ 7.4779224],\n",
       "       [11.247547 ],\n",
       "       [ 8.264363 ],\n",
       "       [ 9.763494 ],\n",
       "       [10.473526 ],\n",
       "       [ 8.17172  ],\n",
       "       [ 7.11294  ],\n",
       "       [ 7.662422 ],\n",
       "       [11.684444 ],\n",
       "       [10.336178 ],\n",
       "       [11.073332 ],\n",
       "       [10.216845 ],\n",
       "       [ 6.611228 ],\n",
       "       [ 9.362777 ],\n",
       "       [11.225824 ],\n",
       "       [ 8.882668 ],\n",
       "       [11.283313 ],\n",
       "       [ 9.199262 ],\n",
       "       [ 6.5801764],\n",
       "       [ 6.9302135],\n",
       "       [ 8.958474 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(X_val)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Comparison to linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2415.5034 - val_loss: 2385.3982\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2316.4373 - val_loss: 2285.7754\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2218.9314 - val_loss: 2189.9836\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2125.2954 - val_loss: 2096.1021\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2033.5359 - val_loss: 2005.7753\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1946.0413 - val_loss: 1918.6622\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1860.8962 - val_loss: 1834.9708\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1779.5292 - val_loss: 1754.0579\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1701.1117 - val_loss: 1675.9507\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1624.8290 - val_loss: 1600.5135\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1551.7468 - val_loss: 1527.7195\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1480.4453 - val_loss: 1458.0704\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1412.2889 - val_loss: 1390.4873\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1345.8497 - val_loss: 1324.6846\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1282.1936 - val_loss: 1260.9077\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1220.3643 - val_loss: 1201.1349\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1161.9789 - val_loss: 1142.9103\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1105.3046 - val_loss: 1086.8815\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1050.1793 - val_loss: 1033.4369\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 998.5919 - val_loss: 980.5502\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 947.7685 - val_loss: 930.1075\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 898.3627 - val_loss: 882.9022\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 852.4216 - val_loss: 836.6912\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 807.9047 - val_loss: 792.8363\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 765.5448 - val_loss: 751.2625\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 724.6445 - val_loss: 711.8580\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 686.3997 - val_loss: 673.1377\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 649.3596 - val_loss: 636.3529\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 614.2555 - val_loss: 601.7404\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 580.6948 - val_loss: 568.9436\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 549.0065 - val_loss: 537.3903\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 518.2365 - val_loss: 507.0370\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 489.1088 - val_loss: 478.1861\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 461.4601 - val_loss: 451.0618\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 435.0910 - val_loss: 425.4774\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 410.1490 - val_loss: 401.1646\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 386.5231 - val_loss: 377.4621\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 363.7656 - val_loss: 355.1344\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 342.3295 - val_loss: 334.1378\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 322.2074 - val_loss: 314.2654\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 303.1973 - val_loss: 295.4857\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 285.2401 - val_loss: 277.8304\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 267.8896 - val_loss: 261.0646\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 251.8599 - val_loss: 245.1381\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 236.6956 - val_loss: 230.3122\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 222.4164 - val_loss: 216.4240\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 209.0424 - val_loss: 203.1802\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 196.4043 - val_loss: 190.6946\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 184.4354 - val_loss: 178.9870\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 173.1665 - val_loss: 168.0019\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 162.6596 - val_loss: 157.6202\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 152.6530 - val_loss: 147.8576\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 143.2982 - val_loss: 138.7092\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 134.5065 - val_loss: 130.1550\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 126.2865 - val_loss: 122.1201\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 118.6553 - val_loss: 114.4355\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 111.5227 - val_loss: 107.3432\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 104.7078 - val_loss: 101.0211\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 98.7628 - val_loss: 94.8647\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 92.9164 - val_loss: 89.3098\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 87.6242 - val_loss: 84.1718\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 82.7362 - val_loss: 79.3732\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 78.2297 - val_loss: 74.8956\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 73.9203 - val_loss: 70.8139\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 70.0521 - val_loss: 66.8884\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 66.3504 - val_loss: 63.2409\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 62.9058 - val_loss: 59.8730\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 59.7380 - val_loss: 56.7845\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 56.8503 - val_loss: 53.9569\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 54.1915 - val_loss: 51.3774\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 51.7801 - val_loss: 48.9787\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 49.5390 - val_loss: 46.7803\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 47.5044 - val_loss: 44.7394\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 45.5739 - val_loss: 42.8747\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 43.8185 - val_loss: 41.1519\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 42.2140 - val_loss: 39.5740\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 40.7461 - val_loss: 38.1658\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 39.4050 - val_loss: 36.8399\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 38.2197 - val_loss: 35.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 37.0616 - val_loss: 34.5328\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 36.1012 - val_loss: 33.5325\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 35.1704 - val_loss: 32.6188\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 34.3280 - val_loss: 31.8069\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 33.5654 - val_loss: 31.0433\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 32.8607 - val_loss: 30.3326\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 32.2185 - val_loss: 29.6704\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 31.6277 - val_loss: 29.0814\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 31.0928 - val_loss: 28.5954\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 30.6440 - val_loss: 28.1162\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 30.2011 - val_loss: 27.6851\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 29.8145 - val_loss: 27.2492\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 29.4219 - val_loss: 26.9289\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 29.1375 - val_loss: 26.5939\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 28.8356 - val_loss: 26.3147\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 28.5801 - val_loss: 26.0223\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 28.3298 - val_loss: 25.7828\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 28.1268 - val_loss: 25.5624\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.9269 - val_loss: 25.3801\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.7637 - val_loss: 25.2144\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.6215 - val_loss: 25.0439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22055e48130>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the linear regression model\n",
    "regression = Sequential()\n",
    "regression.add(Dense(1, input_shape=(X.shape[1],)))\n",
    "\n",
    "# Train the model\n",
    "regression.compile(optimizer='adam', loss='mean_squared_error')\n",
    "regression.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, \n",
    "               callbacks=[EarlyStopping(patience=3)], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember there is randomness involved when using gradient descent! So if you re-run the training, you may get different results! We can change the stopping criteria or max number of epochs if we notice inconsistent runs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
